# word2vec

Word2vec is a group of related models that are used to produce word embeddings. It can be obtained using two methods (both involving Neural Networks): Skip Gram and Common Bag Of Words (CBOW)



#### Tutorial

https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa